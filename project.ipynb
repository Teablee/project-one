{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Combining\n",
    "\n",
    "#### CSV files from Spotify Charts were imported and merged.\n",
    "Since the CSV files were per week, they were combined based on: https://stackoverflow.com/questions/42756696/read-multiple-csv-files-and-add-filename-as-new-column-in-pandas\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "### CSV combining for May and July"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/top_200/may/*.csv')\n",
    "# print(files)\n",
    "\n",
    "may_combined_df_top200 = pd.concat([pd.read_csv(fp, skiprows=[0], skip_blank_lines=True).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "may_combined_df_top200\n",
    "may_combined_df_top200 = may_combined_df_top200.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_combined_df_top200[\"Month\"] = \"\"\n",
    "may_combined_df_top200['Date'] = may_combined_df_top200['Filename'].str.slice(19,29)\n",
    "may_combined_df_top200['Date'] = pd.to_datetime(may_combined_df_top200['Date'])\n",
    "may_combined_df_top200[\"Week Number\"] = may_combined_df_top200['Date'].dt.week\n",
    "may_combined_df_top200['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in may_combined_df_top200.iterrows():\n",
    "    may_combined_df_top200.loc[index, \"Month\"] = \"May\"\n",
    "    may_combined_df_top200.loc[index, \"Type\"] = \"Top 200\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "may_combined_df_top200.to_csv(\"csv files/may_combined_top200.csv\")\n",
    "\n",
    "\n",
    "\n",
    "may_combined_df_top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/viral/may/*.csv')\n",
    "# print(files)\n",
    "\n",
    "may_combined_df_viral50 = pd.concat([pd.read_csv(fp).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "may_combined_df_viral50\n",
    "may_combined_df_viral50 = may_combined_df_viral50.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_combined_df_viral50[\"Month\"] = \"\"\n",
    "may_combined_df_viral50['Date'] = may_combined_df_viral50['Filename'].str.slice(16,26)\n",
    "may_combined_df_viral50['Date'] = pd.to_datetime(may_combined_df_viral50['Date'])\n",
    "may_combined_df_viral50[\"Week Number\"] = may_combined_df_viral50['Date'].dt.week\n",
    "may_combined_df_viral50['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in may_combined_df_viral50.iterrows():\n",
    "    may_combined_df_viral50.loc[index, \"Month\"] = \"May\"\n",
    "    may_combined_df_viral50.loc[index, \"Type\"] = \"Viral 50\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "may_combined_df_viral50.to_csv(\"csv files/may_combined_viral50.csv\")\n",
    "\n",
    "\n",
    "\n",
    "may_combined_df_viral50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/top_200/jul/*.csv')\n",
    "# print(files)\n",
    "\n",
    "july_combined_df_top200 = pd.concat([pd.read_csv(fp, skiprows=[0], skip_blank_lines=True).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "july_combined_df_top200\n",
    "july_combined_df_top200 = july_combined_df_top200.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_combined_df_top200[\"Month\"] = \"\"\n",
    "july_combined_df_top200['Date'] = july_combined_df_top200['Filename'].str.slice(19,29)\n",
    "july_combined_df_top200['Date'] = pd.to_datetime(july_combined_df_top200['Date'])\n",
    "july_combined_df_top200[\"Week Number\"] = july_combined_df_top200['Date'].dt.week\n",
    "july_combined_df_top200['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in july_combined_df_top200.iterrows():\n",
    "    july_combined_df_top200.loc[index, \"Month\"] = \"July\"\n",
    "    july_combined_df_top200.loc[index, \"Type\"] = \"Top 200\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "july_combined_df_top200.to_csv(\"csv files/july_combined_top200.csv\")\n",
    "\n",
    "\n",
    "\n",
    "july_combined_df_top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/viral/jul/*.csv')\n",
    "# print(files)\n",
    "\n",
    "july_combined_df_viral50 = pd.concat([pd.read_csv(fp).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "july_combined_df_viral50\n",
    "july_combined_df_viral50 = july_combined_df_viral50.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_combined_df_viral50[\"Month\"] = \"\"\n",
    "july_combined_df_viral50['Date'] = july_combined_df_viral50['Filename'].str.slice(16,26)\n",
    "july_combined_df_viral50['Date'] = pd.to_datetime(july_combined_df_viral50['Date'])\n",
    "july_combined_df_viral50[\"Week Number\"] = july_combined_df_viral50['Date'].dt.week\n",
    "july_combined_df_viral50['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in july_combined_df_viral50.iterrows():\n",
    "    july_combined_df_viral50.loc[index, \"Month\"] = \"July\"\n",
    "    july_combined_df_viral50.loc[index, \"Type\"] = \"Viral 50\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "july_combined_df_viral50.to_csv(\"csv files/july_combined_viral50.csv\")\n",
    "\n",
    "\n",
    "\n",
    "july_combined_df_viral50"
   ]
  },
  {
   "source": [
    "# Preparing data for graphing\n",
    "### Creating dataframes for the necessary information.\n",
    "\n",
    "The data obtained from the "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spotify credentials\n",
    "client_id = 'client_id'\n",
    "client_secret = 'client_secret'\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)'\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'jan_viral_50.csv'\n",
    "jan_viral_df = pd.read_csv(csv_path)\n",
    "jan_viral_df.head()\n",
    "jan_viral_df['Artist ID'] = \"\"\n",
    "jan_viral_df['Genre 1'] = \"\"\n",
    "jan_viral_df['Genre 2'] = \"\"\n",
    "jan_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in jan_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    jan_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in jan_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        jan_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        jan_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        jan_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "jan_viral_df.head()"
   ]
  }
 ]
}