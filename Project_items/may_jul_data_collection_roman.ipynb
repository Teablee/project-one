{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notes to the graders\n",
    "\n",
    "# Each of us pulled and cleaned data for 2 months of each top 200 and viral 50 charts --- the data wrangling parts are in separate notebooks for each of us. The code for the collection notebooks will not run without entering your own ID and secert ID for the spotify API. \n",
    "\n",
    "# We all worked on separate parts of the graphing and analysis and combined that into one jupyter notebook named \"Graphing.\" This notebook is broken out into sections by name as well, but the code here is runable and the whole notebook is a compilation of how we approached creating our final graphs for the presentation.\n",
    "\n",
    "# Created csv files are stored in the 'csv files' folder and created/saved graphs are stored in the 'Images' folder."
   ]
  },
  {
   "source": [
    "# Data Combining\n",
    "\n",
    "#### CSV files from Spotify Charts were imported and merged.\n",
    "Since the CSV files were per week, they were combined based on: https://stackoverflow.com/questions/42756696/read-multiple-csv-files-and-add-filename-as-new-column-in-pandas\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import scipy.stats as st"
   ]
  },
  {
   "source": [
    "### CSV combining for May and July"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/top_200/may/*.csv')\n",
    "# print(files)\n",
    "\n",
    "may_combined_df_top200 = pd.concat([pd.read_csv(fp, skiprows=[0], skip_blank_lines=True).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "may_combined_df_top200\n",
    "may_combined_df_top200 = may_combined_df_top200.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_combined_df_top200[\"Month\"] = \"\"\n",
    "may_combined_df_top200['Date'] = may_combined_df_top200['Filename'].str.slice(19,29)\n",
    "may_combined_df_top200['Date'] = pd.to_datetime(may_combined_df_top200['Date'])\n",
    "may_combined_df_top200[\"Week Number\"] = may_combined_df_top200['Date'].dt.week\n",
    "may_combined_df_top200['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in may_combined_df_top200.iterrows():\n",
    "    may_combined_df_top200.loc[index, \"Month\"] = \"May\"\n",
    "    may_combined_df_top200.loc[index, \"Type\"] = \"Top 200\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "may_combined_df_top200.to_csv(\"csv files/may_combined_top200.csv\")\n",
    "\n",
    "\n",
    "\n",
    "may_combined_df_top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/viral/may/*.csv')\n",
    "# print(files)\n",
    "\n",
    "may_combined_df_viral50 = pd.concat([pd.read_csv(fp).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "may_combined_df_viral50\n",
    "may_combined_df_viral50 = may_combined_df_viral50.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_combined_df_viral50[\"Month\"] = \"\"\n",
    "may_combined_df_viral50['Date'] = may_combined_df_viral50['Filename'].str.slice(16,26)\n",
    "may_combined_df_viral50['Date'] = pd.to_datetime(may_combined_df_viral50['Date'])\n",
    "may_combined_df_viral50[\"Week Number\"] = may_combined_df_viral50['Date'].dt.week\n",
    "may_combined_df_viral50['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in may_combined_df_viral50.iterrows():\n",
    "    may_combined_df_viral50.loc[index, \"Month\"] = \"May\"\n",
    "    may_combined_df_viral50.loc[index, \"Type\"] = \"Viral 50\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "may_combined_df_viral50.to_csv(\"csv files/may_combined_viral50.csv\")\n",
    "\n",
    "\n",
    "\n",
    "may_combined_df_viral50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/top_200/jul/*.csv')\n",
    "# print(files)\n",
    "\n",
    "july_combined_df_top200 = pd.concat([pd.read_csv(fp, skiprows=[0], skip_blank_lines=True).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "july_combined_df_top200\n",
    "july_combined_df_top200 = july_combined_df_top200.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_combined_df_top200[\"Month\"] = \"\"\n",
    "july_combined_df_top200['Date'] = july_combined_df_top200['Filename'].str.slice(19,29)\n",
    "july_combined_df_top200['Date'] = pd.to_datetime(july_combined_df_top200['Date'])\n",
    "july_combined_df_top200[\"Week Number\"] = july_combined_df_top200['Date'].dt.week\n",
    "july_combined_df_top200['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in july_combined_df_top200.iterrows():\n",
    "    july_combined_df_top200.loc[index, \"Month\"] = \"July\"\n",
    "    july_combined_df_top200.loc[index, \"Type\"] = \"Top 200\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "july_combined_df_top200.to_csv(\"csv files/july_combined_top200.csv\")\n",
    "\n",
    "\n",
    "\n",
    "july_combined_df_top200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('Raw_files/viral/jul/*.csv')\n",
    "# print(files)\n",
    "\n",
    "july_combined_df_viral50 = pd.concat([pd.read_csv(fp).assign(Filename=os.path.basename(fp)) for fp in files])\n",
    "\n",
    "july_combined_df_viral50\n",
    "july_combined_df_viral50 = july_combined_df_viral50.sort_values(['Filename', \"Position\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_combined_df_viral50[\"Month\"] = \"\"\n",
    "july_combined_df_viral50['Date'] = july_combined_df_viral50['Filename'].str.slice(16,26)\n",
    "july_combined_df_viral50['Date'] = pd.to_datetime(july_combined_df_viral50['Date'])\n",
    "july_combined_df_viral50[\"Week Number\"] = july_combined_df_viral50['Date'].dt.week\n",
    "july_combined_df_viral50['Type'] = ''\n",
    "\n",
    "\n",
    "for index, row in july_combined_df_viral50.iterrows():\n",
    "    july_combined_df_viral50.loc[index, \"Month\"] = \"July\"\n",
    "    july_combined_df_viral50.loc[index, \"Type\"] = \"Viral 50\"\n",
    "\n",
    "#viral slicing is 16, 26\n",
    "#top 200 slicing is 19,29\n",
    "july_combined_df_viral50.to_csv(\"csv files/july_combined_viral50.csv\")\n",
    "\n",
    "\n",
    "\n",
    "july_combined_df_viral50"
   ]
  },
  {
   "source": [
    "# Preparing data for graphs\n",
    "### Creating dataframes for the necessary information.\n",
    "\n",
    "The data obtained from the Spotify Charts website, saved as csv and combined into months is used to make requests to Spotify API (using spotipy Python library) to get artist, track, and genre. This information is joined with the stream numbers information from the Spotify Charts csv, cleaned and get ready for graphing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spotify credentials\n",
    "client_id = 'client_id'\n",
    "client_secret = 'client_secret'\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)'\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "source": [
    "### <u>Viral 50</u>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### January"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'jan_viral_50.csv'\n",
    "jan_viral_df = pd.read_csv(csv_path)\n",
    "jan_viral_df.head()\n",
    "jan_viral_df['Artist ID'] = \"\"\n",
    "jan_viral_df['Genre 1'] = \"\"\n",
    "jan_viral_df['Genre 2'] = \"\"\n",
    "jan_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in jan_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    jan_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in jan_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        jan_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        jan_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        jan_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "jan_viral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jan_viral_df=jan_viral_df.copy()\n",
    "for index, row in new_jan_viral_df.iterrows():\n",
    "    if row['Genre 1'] == \"\" :\n",
    "        new_jan_viral_df.loc[index, 'Genre 1'] = \"unspecified\"\n",
    "\n",
    "new_jan_viral_df.value_counts('Genre 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jan_viral_df_dropped = new_jan_viral_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "new_jan_viral_df_dropped.head()"
   ]
  },
  {
   "source": [
    "### March"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'mar_viral_50.csv'\n",
    "mar_viral_df = pd.read_csv(csv_path)\n",
    "mar_viral_df.head()\n",
    "mar_viral_df['Artist ID'] = \"\"\n",
    "mar_viral_df['Genre 1'] = \"\"\n",
    "mar_viral_df['Genre 2'] = \"\"\n",
    "mar_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in mar_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    mar_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in mar_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        mar_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        mar_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        mar_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "mar_viral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mar_viral_df=mar_viral_df.copy()\n",
    "for index, row in new_mar_viral_df.iterrows():\n",
    "    if row['Genre 1'] == \"\" :\n",
    "        new_mar_viral_df.loc[index, 'Genre 1'] = \"unspecified\"\n",
    "\n",
    "new_mar_viral_df.value_counts('Genre 1')"
   ]
  },
  {
   "source": [
    "### May"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'may_combined_df_viral50.csv'\n",
    "may_viral_df = pd.read_csv(csv_path)\n",
    "may_viral_df.head()\n",
    "\n",
    "# Make blank column for storing the artist ID\n",
    "may_viral_df['Artist ID'] = \"\"\n",
    "may_viral_df['Genre 1'] = \"\"\n",
    "may_viral_df['Genre 2'] = \"\"\n",
    "may_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in may_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    may_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in may_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        may_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        may_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        may_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_may_viral_df=may_viral_df.copy()\n",
    "for index, row in new_may_viral_df.iterrows():\n",
    "    if row['Genre 1'] == \"\" :\n",
    "        new_may_viral_df.loc[index, 'Genre 1'] = \"unspecified\"\n",
    "\n",
    "new_may_viral_df.value_counts('Genre 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_may_viral_df_dropped = new_may_viral_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "new_may_viral_df_dropped.head()"
   ]
  },
  {
   "source": [
    "### July"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'july_combined_df_viral50.csv'\n",
    "jul_viral_df = pd.read_csv(csv_path)\n",
    "jul_viral_df.head()\n",
    "\n",
    "# Make blank column for storing the artist ID\n",
    "jul_viral_df['Artist ID'] = \"\"\n",
    "jul_viral_df['Genre 1'] = \"\"\n",
    "jul_viral_df['Genre 2'] = \"\"\n",
    "jul_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in jul_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    jul_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in jul_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        jul_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        jul_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        jul_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jul_viral_df=jul_viral_df.copy()\n",
    "for index, row in new_jul_viral_df.iterrows():\n",
    "    if row['Genre 1'] == \"\" :\n",
    "        new_jul_viral_df.loc[index, 'Genre 1'] = \"unspecified\"\n",
    "\n",
    "new_jul_viral_df.value_counts('Genre 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jul_viral_df_dropped = new_jul_viral_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "new_jul_viral_df_dropped.head()"
   ]
  },
  {
   "source": [
    "### September"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'sept_combined_viral.csv'\n",
    "sep_viral_df = pd.read_csv(csv_path)\n",
    "sep_viral_df.head()\n",
    "\n",
    "# Make blank column for storing the artist ID\n",
    "sep_viral_df['Artist ID'] = \"\"\n",
    "sep_viral_df['Genre 1'] = \"\"\n",
    "sep_viral_df['Genre 2'] = \"\"\n",
    "sep_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in sep_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    sep_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in sep_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        sep_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        sep_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        sep_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sep_viral_df=sep_viral_df.copy()\n",
    "for index, row in new_sep_viral_df.iterrows():\n",
    "    if row['Genre 1'] == \"\" :\n",
    "        new_sep_viral_df.loc[index, 'Genre 1'] = \"unspecified\"\n",
    "\n",
    "new_sep_viral_df.value_counts('Genre 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sep_viral_df_dropped = new_sep_viral_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "new_sep_viral_df_dropped.head()"
   ]
  },
  {
   "source": [
    "### November"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'nov_combined_viral.csv'\n",
    "nov_viral_df = pd.read_csv(csv_path)\n",
    "nov_viral_df.head()\n",
    "\n",
    "# Make blank column for storing the artist ID\n",
    "nov_viral_df['Artist ID'] = \"\"\n",
    "nov_viral_df['Genre 1'] = \"\"\n",
    "nov_viral_df['Genre 2'] = \"\"\n",
    "nov_viral_df['Genre 3'] = \"\"\n",
    "# Make empty list to collect the artist ID\n",
    "artist_id = []\n",
    "\n",
    "for index, row in nov_viral_df.iterrows():\n",
    "\n",
    "    track_id = row['URL']\n",
    "    track_features = sp.track(track_id)\n",
    "    # print(track_features)\n",
    "    # viral_df.loc[index, 'Artist ID'] \n",
    "    # artist_id.append(track_features['album']['artists'][0]['id'])\n",
    "    nov_viral_df.loc[index, 'Artist ID'] = track_features['album']['artists'][0]['id']\n",
    "\n",
    "for index, row in nov_viral_df.iterrows():\n",
    "\n",
    "    genre_id = row['Artist ID']\n",
    "    artist_features = sp.artist(genre_id)\n",
    "    try:\n",
    "        nov_viral_df.loc[index, 'Genre 1'] = artist_features['genres'][0]\n",
    "        nov_viral_df.loc[index, 'Genre 2'] = artist_features['genres'][1]\n",
    "        nov_viral_df.loc[index, 'Genre 3'] = artist_features['genres'][2]\n",
    "    except (IndexError, KeyError):\n",
    "        print(f'Index {index} genre not found... skipped')\n",
    "    \n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nov_viral_df=nov_viral_df.copy()\n",
    "for index, row in new_nov_viral_df.iterrows():\n",
    "    if row['Genre 1'] == \"\" :\n",
    "        new_nov_viral_df.loc[index, 'Genre 1'] = \"unspecified\"\n",
    "\n",
    "new_nov_viral_df.value_counts('Genre 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nov_viral_df_dropped = new_nov_viral_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "new_nov_viral_df_dropped.head()"
   ]
  },
  {
   "source": [
    "Combining all dataframes and export to CSV to be used for total/all months information."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dataframes and reindex\n",
    "viral_all_df_reindex = pd.concat([new_jan_viral_df_dropped, new_mar_viral_df_dropped, new_may_viral_df_dropped,new_jul_viral_df_dropped, new_sep_viral_df_dropped, new_nov_viral_df_dropped], ignore_index=True)\n",
    "viral_all_df_reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "viral_all_df_reindex.to_csv('viral_all.csv')"
   ]
  },
  {
   "source": [
    "## Obtaining genre data from dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### <u>Viral 50</u>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### January"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('rap|hip hop|trap') | new_jan_viral_df['Genre 2'].str.contains('rap|hip hop|trap') | new_jan_viral_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('r&b|soul|blues') | new_jan_viral_df['Genre 2'].str.contains('r&b|soul|blues') | new_jan_viral_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('pop') | new_jan_viral_df['Genre 2'].str.contains('pop') | new_jan_viral_df['Genre 3'].str.contains('pop')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('rock') | new_jan_viral_df['Genre 2'].str.contains('rock') | new_jan_viral_df['Genre 3'].str.contains('rock')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('country') | new_jan_viral_df['Genre 2'].str.contains('country') | new_jan_viral_df['Genre 3'].str.contains('country')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('latin') | new_jan_viral_df['Genre 2'].str.contains('latin') | new_jan_viral_df['Genre 3'].str.contains('latin')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('disco') | new_jan_viral_df['Genre 2'].str.contains('disco') | new_jan_viral_df['Genre 3'].str.contains('disco')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('indie') | new_jan_viral_df['Genre 2'].str.contains('indie') | new_jan_viral_df['Genre 3'].str.contains('indie')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('house|edm') | new_jan_viral_df['Genre 2'].str.contains('house|edm') | new_jan_viral_df['Genre 3'].str.contains('house|edm')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('alt|alternative') | new_jan_viral_df['Genre 2'].str.contains('alt|alternative') | new_jan_viral_df['Genre 3'].str.contains('alt|alternative')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('glitchcore') | new_jan_viral_df['Genre 2'].str.contains('glitchcore') | new_jan_viral_df['Genre 3'].str.contains('glitchcore')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('brooklyn drill') | new_jan_viral_df['Genre 2'].str.contains('brooklyn drill') | new_jan_viral_df['Genre 3'].str.contains('brooklyn drill')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('halloween') | new_jan_viral_df['Genre 2'].str.contains('halloween') | new_jan_viral_df['Genre 3'].str.contains('halloween')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('christmas') | new_jan_viral_df['Genre 2'].str.contains('christmas') | new_jan_viral_df['Genre 3'].str.contains('christmas')]), len(new_jan_viral_df[new_jan_viral_df['Genre 1'].str.contains('classical') | new_jan_viral_df['Genre 2'].str.contains('classical') | new_jan_viral_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "jan_genre_df = pd.DataFrame(genre_data)\n",
    "jan_genre_df.head()"
   ]
  },
  {
   "source": [
    "### March"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('rap|hip hop|trap') | new_mar_viral_df['Genre 2'].str.contains('rap|hip hop|trap') | new_mar_viral_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('r&b|soul|blues') | new_mar_viral_df['Genre 2'].str.contains('r&b|soul|blues') | new_mar_viral_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('pop') | new_mar_viral_df['Genre 2'].str.contains('pop') | new_mar_viral_df['Genre 3'].str.contains('pop')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('rock') | new_mar_viral_df['Genre 2'].str.contains('rock') | new_mar_viral_df['Genre 3'].str.contains('rock')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('country') | new_mar_viral_df['Genre 2'].str.contains('country') | new_mar_viral_df['Genre 3'].str.contains('country')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('latin') | new_mar_viral_df['Genre 2'].str.contains('latin') | new_mar_viral_df['Genre 3'].str.contains('latin')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('disco') | new_mar_viral_df['Genre 2'].str.contains('disco') | new_mar_viral_df['Genre 3'].str.contains('disco')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('indie') | new_mar_viral_df['Genre 2'].str.contains('indie') | new_mar_viral_df['Genre 3'].str.contains('indie')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('house|edm') | new_mar_viral_df['Genre 2'].str.contains('house|edm') | new_mar_viral_df['Genre 3'].str.contains('house|edm')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('alt|alternative') | new_mar_viral_df['Genre 2'].str.contains('alt|alternative') | new_mar_viral_df['Genre 3'].str.contains('alt|alternative')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('glitchcore') | new_mar_viral_df['Genre 2'].str.contains('glitchcore') | new_mar_viral_df['Genre 3'].str.contains('glitchcore')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('brooklyn drill') | new_mar_viral_df['Genre 2'].str.contains('brooklyn drill') | new_mar_viral_df['Genre 3'].str.contains('brooklyn drill')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('halloween') | new_mar_viral_df['Genre 2'].str.contains('halloween') | new_mar_viral_df['Genre 3'].str.contains('halloween')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('christmas') | new_mar_viral_df['Genre 2'].str.contains('christmas') | new_mar_viral_df['Genre 3'].str.contains('christmas')]), len(new_mar_viral_df[new_mar_viral_df['Genre 1'].str.contains('classical') | new_mar_viral_df['Genre 2'].str.contains('classical') | new_mar_viral_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "mar_genre_df = pd.DataFrame(genre_data)\n",
    "mar_genre_df.head()"
   ]
  },
  {
   "source": [
    "### May"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('rap|hip hop|trap') | new_may_viral_df['Genre 2'].str.contains('rap|hip hop|trap') | new_may_viral_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('r&b|soul|blues') | new_may_viral_df['Genre 2'].str.contains('r&b|soul|blues') | new_may_viral_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('pop') | new_may_viral_df['Genre 2'].str.contains('pop') | new_may_viral_df['Genre 3'].str.contains('pop')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('rock') | new_may_viral_df['Genre 2'].str.contains('rock') | new_may_viral_df['Genre 3'].str.contains('rock')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('country') | new_may_viral_df['Genre 2'].str.contains('country') | new_may_viral_df['Genre 3'].str.contains('country')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('latin') | new_may_viral_df['Genre 2'].str.contains('latin') | new_may_viral_df['Genre 3'].str.contains('latin')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('disco') | new_may_viral_df['Genre 2'].str.contains('disco') | new_may_viral_df['Genre 3'].str.contains('disco')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('indie') | new_may_viral_df['Genre 2'].str.contains('indie') | new_may_viral_df['Genre 3'].str.contains('indie')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('house|edm') | new_may_viral_df['Genre 2'].str.contains('house|edm') | new_may_viral_df['Genre 3'].str.contains('house|edm')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('alt|alternative') | new_may_viral_df['Genre 2'].str.contains('alt|alternative') | new_may_viral_df['Genre 3'].str.contains('alt|alternative')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('glitchcore') | new_may_viral_df['Genre 2'].str.contains('glitchcore') | new_may_viral_df['Genre 3'].str.contains('glitchcore')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('brooklyn drill') | new_may_viral_df['Genre 2'].str.contains('brooklyn drill') | new_may_viral_df['Genre 3'].str.contains('brooklyn drill')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('halloween') | new_may_viral_df['Genre 2'].str.contains('halloween') | new_may_viral_df['Genre 3'].str.contains('halloween')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('christmas') | new_may_viral_df['Genre 2'].str.contains('christmas') | new_may_viral_df['Genre 3'].str.contains('christmas')]), len(new_may_viral_df[new_may_viral_df['Genre 1'].str.contains('classical') | new_may_viral_df['Genre 2'].str.contains('classical') | new_may_viral_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "may_genre_df = pd.DataFrame(genre_data)\n",
    "may_genre_df.head()"
   ]
  },
  {
   "source": [
    "### July"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('rap|hip hop|trap') | new_jul_viral_df['Genre 2'].str.contains('rap|hip hop|trap') | new_jul_viral_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('r&b|soul|blues') | new_jul_viral_df['Genre 2'].str.contains('r&b|soul|blues') | new_jul_viral_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('pop') | new_jul_viral_df['Genre 2'].str.contains('pop') | new_jul_viral_df['Genre 3'].str.contains('pop')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('rock') | new_jul_viral_df['Genre 2'].str.contains('rock') | new_jul_viral_df['Genre 3'].str.contains('rock')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('country') | new_jul_viral_df['Genre 2'].str.contains('country') | new_jul_viral_df['Genre 3'].str.contains('country')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('latin') | new_jul_viral_df['Genre 2'].str.contains('latin') | new_jul_viral_df['Genre 3'].str.contains('latin')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('disco') | new_jul_viral_df['Genre 2'].str.contains('disco') | new_jul_viral_df['Genre 3'].str.contains('disco')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('indie') | new_jul_viral_df['Genre 2'].str.contains('indie') | new_jul_viral_df['Genre 3'].str.contains('indie')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('house|edm') | new_jul_viral_df['Genre 2'].str.contains('house|edm') | new_jul_viral_df['Genre 3'].str.contains('house|edm')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('alt|alternative') | new_jul_viral_df['Genre 2'].str.contains('alt|alternative') | new_jul_viral_df['Genre 3'].str.contains('alt|alternative')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('glitchcore') | new_jul_viral_df['Genre 2'].str.contains('glitchcore') | new_jul_viral_df['Genre 3'].str.contains('glitchcore')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('brooklyn drill') | new_jul_viral_df['Genre 2'].str.contains('brooklyn drill') | new_jul_viral_df['Genre 3'].str.contains('brooklyn drill')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('halloween') | new_jul_viral_df['Genre 2'].str.contains('halloween') | new_jul_viral_df['Genre 3'].str.contains('halloween')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('christmas') | new_jul_viral_df['Genre 2'].str.contains('christmas') | new_jul_viral_df['Genre 3'].str.contains('christmas')]), len(new_jul_viral_df[new_jul_viral_df['Genre 1'].str.contains('classical') | new_jul_viral_df['Genre 2'].str.contains('classical') | new_jul_viral_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "jul_genre_df = pd.DataFrame(genre_data)\n",
    "jul_genre_df.head()"
   ]
  },
  {
   "source": [
    "### September"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('rap|hip hop|trap') | new_sep_viral_df['Genre 2'].str.contains('rap|hip hop|trap') | new_sep_viral_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('r&b|soul|blues') | new_sep_viral_df['Genre 2'].str.contains('r&b|soul|blues') | new_sep_viral_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('pop') | new_sep_viral_df['Genre 2'].str.contains('pop') | new_sep_viral_df['Genre 3'].str.contains('pop')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('rock') | new_sep_viral_df['Genre 2'].str.contains('rock') | new_sep_viral_df['Genre 3'].str.contains('rock')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('country') | new_sep_viral_df['Genre 2'].str.contains('country') | new_sep_viral_df['Genre 3'].str.contains('country')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('latin') | new_sep_viral_df['Genre 2'].str.contains('latin') | new_sep_viral_df['Genre 3'].str.contains('latin')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('disco') | new_sep_viral_df['Genre 2'].str.contains('disco') | new_sep_viral_df['Genre 3'].str.contains('disco')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('indie') | new_sep_viral_df['Genre 2'].str.contains('indie') | new_sep_viral_df['Genre 3'].str.contains('indie')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('house|edm') | new_sep_viral_df['Genre 2'].str.contains('house|edm') | new_sep_viral_df['Genre 3'].str.contains('house|edm')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('alt|alternative') | new_sep_viral_df['Genre 2'].str.contains('alt|alternative') | new_sep_viral_df['Genre 3'].str.contains('alt|alternative')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('glitchcore') | new_sep_viral_df['Genre 2'].str.contains('glitchcore') | new_sep_viral_df['Genre 3'].str.contains('glitchcore')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('brooklyn drill') | new_sep_viral_df['Genre 2'].str.contains('brooklyn drill') | new_sep_viral_df['Genre 3'].str.contains('brooklyn drill')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('halloween') | new_sep_viral_df['Genre 2'].str.contains('halloween') | new_sep_viral_df['Genre 3'].str.contains('halloween')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('christmas') | new_sep_viral_df['Genre 2'].str.contains('christmas') | new_sep_viral_df['Genre 3'].str.contains('christmas')]), len(new_sep_viral_df[new_sep_viral_df['Genre 1'].str.contains('classical') | new_sep_viral_df['Genre 2'].str.contains('classical') | new_sep_viral_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "sep_genre_df = pd.DataFrame(genre_data)\n",
    "sep_genre_df.head()"
   ]
  },
  {
   "source": [
    "### November"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('rap|hip hop|trap') | new_nov_viral_df['Genre 2'].str.contains('rap|hip hop|trap') | new_nov_viral_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('r&b|soul|blues') | new_nov_viral_df['Genre 2'].str.contains('r&b|soul|blues') | new_nov_viral_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('pop') | new_nov_viral_df['Genre 2'].str.contains('pop') | new_nov_viral_df['Genre 3'].str.contains('pop')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('rock') | new_nov_viral_df['Genre 2'].str.contains('rock') | new_nov_viral_df['Genre 3'].str.contains('rock')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('country') | new_nov_viral_df['Genre 2'].str.contains('country') | new_nov_viral_df['Genre 3'].str.contains('country')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('latin') | new_nov_viral_df['Genre 2'].str.contains('latin') | new_nov_viral_df['Genre 3'].str.contains('latin')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('disco') | new_nov_viral_df['Genre 2'].str.contains('disco') | new_nov_viral_df['Genre 3'].str.contains('disco')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('indie') | new_nov_viral_df['Genre 2'].str.contains('indie') | new_nov_viral_df['Genre 3'].str.contains('indie')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('house|edm') | new_nov_viral_df['Genre 2'].str.contains('house|edm') | new_nov_viral_df['Genre 3'].str.contains('house|edm')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('alt|alternative') | new_nov_viral_df['Genre 2'].str.contains('alt|alternative') | new_nov_viral_df['Genre 3'].str.contains('alt|alternative')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('glitchcore') | new_nov_viral_df['Genre 2'].str.contains('glitchcore') | new_nov_viral_df['Genre 3'].str.contains('glitchcore')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('brooklyn drill') | new_nov_viral_df['Genre 2'].str.contains('brooklyn drill') | new_nov_viral_df['Genre 3'].str.contains('brooklyn drill')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('halloween') | new_nov_viral_df['Genre 2'].str.contains('halloween') | new_nov_viral_df['Genre 3'].str.contains('halloween')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('christmas') | new_nov_viral_df['Genre 2'].str.contains('christmas') | new_nov_viral_df['Genre 3'].str.contains('christmas')]), len(new_nov_viral_df[new_nov_viral_df['Genre 1'].str.contains('classical') | new_nov_viral_df['Genre 2'].str.contains('classical') | new_nov_viral_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "nov_genre_df = pd.DataFrame(genre_data)\n",
    "nov_genre_df.head()"
   ]
  },
  {
   "source": [
    "## Visualizations: Histograms/Bar Graphs for Top Viral Songs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Create and clean dataframes. Plethora of odd genres unified into more general categories (original genre name from API reques was used as guide)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_all_df = pd.read_csv('viral_all.csv')\n",
    "viral_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_viral_all_df=viral_all_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "new_viral_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('rap|hip hop|trap') | new_viral_all_df['Genre 2'].str.contains('rap|hip hop|trap') | new_viral_all_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('r&b|soul|blues') | new_viral_all_df['Genre 2'].str.contains('r&b|soul|blues') | new_viral_all_df['Genre 3'].str.contains('r&b|soul|blues')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('pop') | new_viral_all_df['Genre 2'].str.contains('pop') | new_viral_all_df['Genre 3'].str.contains('pop')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('rock') | new_viral_all_df['Genre 2'].str.contains('rock') | new_viral_all_df['Genre 3'].str.contains('rock')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('country') | new_viral_all_df['Genre 2'].str.contains('country') | new_viral_all_df['Genre 3'].str.contains('country')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('latin') | new_viral_all_df['Genre 2'].str.contains('latin') | new_viral_all_df['Genre 3'].str.contains('latin')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('disco') | new_viral_all_df['Genre 2'].str.contains('disco') | new_viral_all_df['Genre 3'].str.contains('disco')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('indie') | new_viral_all_df['Genre 2'].str.contains('indie') | new_viral_all_df['Genre 3'].str.contains('indie')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('house|edm') | new_viral_all_df['Genre 2'].str.contains('house|edm') | new_viral_all_df['Genre 3'].str.contains('house|edm')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('alt|alternative') | new_viral_all_df['Genre 2'].str.contains('alt|alternative') | new_viral_all_df['Genre 3'].str.contains('alt|alternative')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('glitchcore') | new_viral_all_df['Genre 2'].str.contains('glitchcore') | new_viral_all_df['Genre 3'].str.contains('glitchcore')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('brooklyn drill') | new_viral_all_df['Genre 2'].str.contains('brooklyn drill') | new_viral_all_df['Genre 3'].str.contains('brooklyn drill')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('halloween') | new_viral_all_df['Genre 2'].str.contains('halloween') | new_viral_all_df['Genre 3'].str.contains('halloween')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('christmas') | new_viral_all_df['Genre 2'].str.contains('christmas') | new_viral_all_df['Genre 3'].str.contains('christmas')]), len(new_viral_all_df[new_viral_all_df['Genre 1'].str.contains('classical') | new_viral_all_df['Genre 2'].str.contains('classical') | new_viral_all_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "all_viral_genre_df = pd.DataFrame(genre_data)\n",
    "all_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = all_viral_genre_df['Count'].max()\n",
    "print(max_count)\n",
    "percent_total_max = (max_count/all_viral_genre_df['Count'].sum())*100\n",
    "print(percent_total_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_viral_genre_df['Percent']=(all_viral_genre_df['Count']/all_viral_genre_df['Count'].sum())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_viral_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_all_viral_genre_df = all_viral_genre_df.sort_values('Count', ascending=False)"
   ]
  },
  {
   "source": [
    "### <u>Top Viral Genres Distribution Throughout 2020 (Sampled Months)</u>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assign specific colors to genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical']\n",
    "colors = ['red', 'blue', 'purple', 'orchid', 'orange', 'indianred', 'gold', 'seagreen', 'slateblue', 'coral', 'silver', 'palevioletred', 'limegreen', 'maroon', 'purple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_all = sorted_all_viral_genre_df['Genre'].tolist()\n",
    "all_colors = []\n",
    "\n",
    "for x in genres_all:\n",
    "    if x == genres[0]:\n",
    "        all_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        all_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        all_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        all_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        all_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        all_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        all_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        all_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        all_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        all_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        all_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        all_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        all_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        all_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        all_colors.append(colors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sorted_all_viral_genre_df['Genre']\n",
    "values = sorted_all_viral_genre_df['Count'].astype(float)\n",
    "\n",
    "plt.bar(names, values, color=all_colors, zorder=2)\n",
    "plt.xticks(rotation=90, size=14)\n",
    "plt.grid(alpha=0.5, zorder=0)\n",
    "plt.yticks(size=14)\n",
    "plt.ylabel(\"Counts\", size=14)\n",
    "plt.title(\"Total Distribution of Viral Song Genres for Sampled Months in 2020\", size=18)\n",
    "\n",
    "plt.gcf().set_size_inches(15,10)\n",
    "plt.savefig('total_all_viral_genre.jpg', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Distribution of Genres per Month"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Create and clean dataframes. Plethora of odd genres unified into more general categories (original genre name from API reques was used as guide)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = new_viral_all_df[new_viral_all_df['Month'] == 'January']\n",
    "jan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(jan_df[jan_df['Genre 1'].str.contains('rap|hip hop|trap') | jan_df['Genre 2'].str.contains('rap|hip hop|trap') | jan_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(jan_df[jan_df['Genre 1'].str.contains('r&b|soul|blues') | jan_df['Genre 2'].str.contains('r&b|soul|blues') | jan_df['Genre 3'].str.contains('r&b|soul|blues')]), len(jan_df[jan_df['Genre 1'].str.contains('pop') | jan_df['Genre 2'].str.contains('pop') | jan_df['Genre 3'].str.contains('pop')]), len(jan_df[jan_df['Genre 1'].str.contains('rock') | jan_df['Genre 2'].str.contains('rock') | jan_df['Genre 3'].str.contains('rock')]), len(jan_df[jan_df['Genre 1'].str.contains('country') | jan_df['Genre 2'].str.contains('country') | jan_df['Genre 3'].str.contains('country')]), len(jan_df[jan_df['Genre 1'].str.contains('latin') | jan_df['Genre 2'].str.contains('latin') | jan_df['Genre 3'].str.contains('latin')]), len(jan_df[jan_df['Genre 1'].str.contains('disco') | jan_df['Genre 2'].str.contains('disco') | jan_df['Genre 3'].str.contains('disco')]), len(jan_df[jan_df['Genre 1'].str.contains('indie') | jan_df['Genre 2'].str.contains('indie') | jan_df['Genre 3'].str.contains('indie')]), len(jan_df[jan_df['Genre 1'].str.contains('house|edm') | jan_df['Genre 2'].str.contains('house|edm') | jan_df['Genre 3'].str.contains('house|edm')]), len(jan_df[jan_df['Genre 1'].str.contains('alt|alternative') | jan_df['Genre 2'].str.contains('alt|alternative') | jan_df['Genre 3'].str.contains('alt|alternative')]), len(jan_df[jan_df['Genre 1'].str.contains('glitchcore') | jan_df['Genre 2'].str.contains('glitchcore') | jan_df['Genre 3'].str.contains('glitchcore')]), len(jan_df[jan_df['Genre 1'].str.contains('brooklyn drill') | jan_df['Genre 2'].str.contains('brooklyn drill') | jan_df['Genre 3'].str.contains('brooklyn drill')]), len(jan_df[jan_df['Genre 1'].str.contains('halloween') | jan_df['Genre 2'].str.contains('halloween') | jan_df['Genre 3'].str.contains('halloween')]), len(jan_df[jan_df['Genre 1'].str.contains('christmas') | jan_df['Genre 2'].str.contains('christmas') | jan_df['Genre 3'].str.contains('christmas')]), len(jan_df[jan_df['Genre 1'].str.contains('classical') | jan_df['Genre 2'].str.contains('classical') | jan_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "jan_viral_genre_df = pd.DataFrame(genre_data)\n",
    "jan_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_jan_viral_genre_df = jan_viral_genre_df.sort_values('Count', ascending=False)\n",
    "sorted_jan_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_df = new_viral_all_df[new_viral_all_df['Month'] == 'March']\n",
    "mar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(mar_df[mar_df['Genre 1'].str.contains('rap|hip hop|trap') | mar_df['Genre 2'].str.contains('rap|hip hop|trap') | mar_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(mar_df[mar_df['Genre 1'].str.contains('r&b|soul|blues') | mar_df['Genre 2'].str.contains('r&b|soul|blues') | mar_df['Genre 3'].str.contains('r&b|soul|blues')]), len(mar_df[mar_df['Genre 1'].str.contains('pop') | mar_df['Genre 2'].str.contains('pop') | mar_df['Genre 3'].str.contains('pop')]), len(mar_df[mar_df['Genre 1'].str.contains('rock') | mar_df['Genre 2'].str.contains('rock') | mar_df['Genre 3'].str.contains('rock')]), len(mar_df[mar_df['Genre 1'].str.contains('country') | mar_df['Genre 2'].str.contains('country') | mar_df['Genre 3'].str.contains('country')]), len(mar_df[mar_df['Genre 1'].str.contains('latin') | mar_df['Genre 2'].str.contains('latin') | mar_df['Genre 3'].str.contains('latin')]), len(mar_df[mar_df['Genre 1'].str.contains('disco') | mar_df['Genre 2'].str.contains('disco') | mar_df['Genre 3'].str.contains('disco')]), len(mar_df[mar_df['Genre 1'].str.contains('indie') | mar_df['Genre 2'].str.contains('indie') | mar_df['Genre 3'].str.contains('indie')]), len(mar_df[mar_df['Genre 1'].str.contains('house|edm') | mar_df['Genre 2'].str.contains('house|edm') | mar_df['Genre 3'].str.contains('house|edm')]), len(mar_df[mar_df['Genre 1'].str.contains('alt|alternative') | mar_df['Genre 2'].str.contains('alt|alternative') | mar_df['Genre 3'].str.contains('alt|alternative')]), len(mar_df[mar_df['Genre 1'].str.contains('glitchcore') | mar_df['Genre 2'].str.contains('glitchcore') | mar_df['Genre 3'].str.contains('glitchcore')]), len(mar_df[mar_df['Genre 1'].str.contains('brooklyn drill') | mar_df['Genre 2'].str.contains('brooklyn drill') | mar_df['Genre 3'].str.contains('brooklyn drill')]), len(mar_df[mar_df['Genre 1'].str.contains('halloween') | mar_df['Genre 2'].str.contains('halloween') | mar_df['Genre 3'].str.contains('halloween')]), len(mar_df[mar_df['Genre 1'].str.contains('christmas') | mar_df['Genre 2'].str.contains('christmas') | mar_df['Genre 3'].str.contains('christmas')]), len(mar_df[mar_df['Genre 1'].str.contains('classical') | mar_df['Genre 2'].str.contains('classical') | mar_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "mar_viral_genre_df = pd.DataFrame(genre_data)\n",
    "mar_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mar_viral_genre_df = mar_viral_genre_df.sort_values('Count', ascending=False)\n",
    "sorted_mar_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df = new_viral_all_df[new_viral_all_df['Month'] == 'May']\n",
    "may_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(may_df[may_df['Genre 1'].str.contains('rap|hip hop|trap') | may_df['Genre 2'].str.contains('rap|hip hop|trap') | may_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(may_df[may_df['Genre 1'].str.contains('r&b|soul|blues') | may_df['Genre 2'].str.contains('r&b|soul|blues') | may_df['Genre 3'].str.contains('r&b|soul|blues')]), len(may_df[may_df['Genre 1'].str.contains('pop') | may_df['Genre 2'].str.contains('pop') | may_df['Genre 3'].str.contains('pop')]), len(may_df[may_df['Genre 1'].str.contains('rock') | may_df['Genre 2'].str.contains('rock') | may_df['Genre 3'].str.contains('rock')]), len(may_df[may_df['Genre 1'].str.contains('country') | may_df['Genre 2'].str.contains('country') | may_df['Genre 3'].str.contains('country')]), len(may_df[may_df['Genre 1'].str.contains('latin') | may_df['Genre 2'].str.contains('latin') | may_df['Genre 3'].str.contains('latin')]), len(may_df[may_df['Genre 1'].str.contains('disco') | may_df['Genre 2'].str.contains('disco') | may_df['Genre 3'].str.contains('disco')]), len(may_df[may_df['Genre 1'].str.contains('indie') | may_df['Genre 2'].str.contains('indie') | may_df['Genre 3'].str.contains('indie')]), len(may_df[may_df['Genre 1'].str.contains('house|edm') | may_df['Genre 2'].str.contains('house|edm') | may_df['Genre 3'].str.contains('house|edm')]), len(may_df[may_df['Genre 1'].str.contains('alt|alternative') | may_df['Genre 2'].str.contains('alt|alternative') | may_df['Genre 3'].str.contains('alt|alternative')]), len(may_df[may_df['Genre 1'].str.contains('glitchcore') | may_df['Genre 2'].str.contains('glitchcore') | may_df['Genre 3'].str.contains('glitchcore')]), len(may_df[may_df['Genre 1'].str.contains('brooklyn drill') | may_df['Genre 2'].str.contains('brooklyn drill') | may_df['Genre 3'].str.contains('brooklyn drill')]), len(may_df[may_df['Genre 1'].str.contains('halloween') | may_df['Genre 2'].str.contains('halloween') | may_df['Genre 3'].str.contains('halloween')]), len(may_df[may_df['Genre 1'].str.contains('christmas') | may_df['Genre 2'].str.contains('christmas') | may_df['Genre 3'].str.contains('christmas')]), len(may_df[may_df['Genre 1'].str.contains('classical') | may_df['Genre 2'].str.contains('classical') | may_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "may_viral_genre_df = pd.DataFrame(genre_data)\n",
    "may_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_may_viral_genre_df = may_viral_genre_df.sort_values('Count', ascending=False)\n",
    "sorted_may_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jul_df = new_viral_all_df[new_viral_all_df['Month'] == 'July']\n",
    "jul_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(jul_df[jul_df['Genre 1'].str.contains('rap|hip hop|trap') | jul_df['Genre 2'].str.contains('rap|hip hop|trap') | jul_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(jul_df[jul_df['Genre 1'].str.contains('r&b|soul|blues') | jul_df['Genre 2'].str.contains('r&b|soul|blues') | jul_df['Genre 3'].str.contains('r&b|soul|blues')]), len(jul_df[jul_df['Genre 1'].str.contains('pop') | jul_df['Genre 2'].str.contains('pop') | jul_df['Genre 3'].str.contains('pop')]), len(jul_df[jul_df['Genre 1'].str.contains('rock') | jul_df['Genre 2'].str.contains('rock') | jul_df['Genre 3'].str.contains('rock')]), len(jul_df[jul_df['Genre 1'].str.contains('country') | jul_df['Genre 2'].str.contains('country') | jul_df['Genre 3'].str.contains('country')]), len(jul_df[jul_df['Genre 1'].str.contains('latin') | jul_df['Genre 2'].str.contains('latin') | jul_df['Genre 3'].str.contains('latin')]), len(jul_df[jul_df['Genre 1'].str.contains('disco') | jul_df['Genre 2'].str.contains('disco') | jul_df['Genre 3'].str.contains('disco')]), len(jul_df[jul_df['Genre 1'].str.contains('indie') | jul_df['Genre 2'].str.contains('indie') | jul_df['Genre 3'].str.contains('indie')]), len(jul_df[jul_df['Genre 1'].str.contains('house|edm') | jul_df['Genre 2'].str.contains('house|edm') | jul_df['Genre 3'].str.contains('house|edm')]), len(jul_df[jul_df['Genre 1'].str.contains('alt|alternative') | jul_df['Genre 2'].str.contains('alt|alternative') | jul_df['Genre 3'].str.contains('alt|alternative')]), len(jul_df[jul_df['Genre 1'].str.contains('glitchcore') | jul_df['Genre 2'].str.contains('glitchcore') | jul_df['Genre 3'].str.contains('glitchcore')]), len(jul_df[jul_df['Genre 1'].str.contains('brooklyn drill') | jul_df['Genre 2'].str.contains('brooklyn drill') | jul_df['Genre 3'].str.contains('brooklyn drill')]), len(jul_df[jul_df['Genre 1'].str.contains('halloween') | jul_df['Genre 2'].str.contains('halloween') | jul_df['Genre 3'].str.contains('halloween')]), len(jul_df[jul_df['Genre 1'].str.contains('christmas') | jul_df['Genre 2'].str.contains('christmas') | jul_df['Genre 3'].str.contains('christmas')]), len(jul_df[jul_df['Genre 1'].str.contains('classical') | jul_df['Genre 2'].str.contains('classical') | jul_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "jul_viral_genre_df = pd.DataFrame(genre_data)\n",
    "jul_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_jul_viral_genre_df = jul_viral_genre_df.sort_values('Count', ascending=False)\n",
    "sorted_jul_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df = new_viral_all_df[new_viral_all_df['Month'] == 'September']\n",
    "sep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(sep_df[sep_df['Genre 1'].str.contains('rap|hip hop|trap') | sep_df['Genre 2'].str.contains('rap|hip hop|trap') | sep_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(sep_df[sep_df['Genre 1'].str.contains('r&b|soul|blues') | sep_df['Genre 2'].str.contains('r&b|soul|blues') | sep_df['Genre 3'].str.contains('r&b|soul|blues')]), len(sep_df[sep_df['Genre 1'].str.contains('pop') | sep_df['Genre 2'].str.contains('pop') | sep_df['Genre 3'].str.contains('pop')]), len(sep_df[sep_df['Genre 1'].str.contains('rock') | sep_df['Genre 2'].str.contains('rock') | sep_df['Genre 3'].str.contains('rock')]), len(sep_df[sep_df['Genre 1'].str.contains('country') | sep_df['Genre 2'].str.contains('country') | sep_df['Genre 3'].str.contains('country')]), len(sep_df[sep_df['Genre 1'].str.contains('latin') | sep_df['Genre 2'].str.contains('latin') | sep_df['Genre 3'].str.contains('latin')]), len(sep_df[sep_df['Genre 1'].str.contains('disco') | sep_df['Genre 2'].str.contains('disco') | sep_df['Genre 3'].str.contains('disco')]), len(sep_df[sep_df['Genre 1'].str.contains('indie') | sep_df['Genre 2'].str.contains('indie') | sep_df['Genre 3'].str.contains('indie')]), len(sep_df[sep_df['Genre 1'].str.contains('house|edm') | sep_df['Genre 2'].str.contains('house|edm') | sep_df['Genre 3'].str.contains('house|edm')]), len(sep_df[sep_df['Genre 1'].str.contains('alt|alternative') | sep_df['Genre 2'].str.contains('alt|alternative') | sep_df['Genre 3'].str.contains('alt|alternative')]), len(sep_df[sep_df['Genre 1'].str.contains('glitchcore') | sep_df['Genre 2'].str.contains('glitchcore') | sep_df['Genre 3'].str.contains('glitchcore')]), len(sep_df[sep_df['Genre 1'].str.contains('brooklyn drill') | sep_df['Genre 2'].str.contains('brooklyn drill') | sep_df['Genre 3'].str.contains('brooklyn drill')]), len(sep_df[sep_df['Genre 1'].str.contains('halloween') | sep_df['Genre 2'].str.contains('halloween') | sep_df['Genre 3'].str.contains('halloween')]), len(sep_df[sep_df['Genre 1'].str.contains('christmas') | sep_df['Genre 2'].str.contains('christmas') | sep_df['Genre 3'].str.contains('christmas')]), len(sep_df[sep_df['Genre 1'].str.contains('classical') | sep_df['Genre 2'].str.contains('classical') | sep_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "sep_viral_genre_df = pd.DataFrame(genre_data)\n",
    "sep_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sep_viral_genre_df = sep_viral_genre_df.sort_values('Count', ascending=False)\n",
    "sorted_sep_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov_df = new_viral_all_df[new_viral_all_df['Month'] == 'November']\n",
    "nov_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data = {\n",
    "    'Genre': ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical'],\n",
    "    'Count': [len(nov_df[nov_df['Genre 1'].str.contains('rap|hip hop|trap') | nov_df['Genre 2'].str.contains('rap|hip hop|trap') | nov_df['Genre 3'].str.contains('rap|hip hop|trap')]), len(nov_df[nov_df['Genre 1'].str.contains('r&b|soul|blues') | nov_df['Genre 2'].str.contains('r&b|soul|blues') | nov_df['Genre 3'].str.contains('r&b|soul|blues')]), len(nov_df[nov_df['Genre 1'].str.contains('pop') | nov_df['Genre 2'].str.contains('pop') | nov_df['Genre 3'].str.contains('pop')]), len(nov_df[nov_df['Genre 1'].str.contains('rock') | nov_df['Genre 2'].str.contains('rock') | nov_df['Genre 3'].str.contains('rock')]), len(nov_df[nov_df['Genre 1'].str.contains('country') | nov_df['Genre 2'].str.contains('country') | nov_df['Genre 3'].str.contains('country')]), len(nov_df[nov_df['Genre 1'].str.contains('latin') | nov_df['Genre 2'].str.contains('latin') | nov_df['Genre 3'].str.contains('latin')]), len(nov_df[nov_df['Genre 1'].str.contains('disco') | nov_df['Genre 2'].str.contains('disco') | nov_df['Genre 3'].str.contains('disco')]), len(nov_df[nov_df['Genre 1'].str.contains('indie') | nov_df['Genre 2'].str.contains('indie') | nov_df['Genre 3'].str.contains('indie')]), len(nov_df[nov_df['Genre 1'].str.contains('house|edm') | nov_df['Genre 2'].str.contains('house|edm') | nov_df['Genre 3'].str.contains('house|edm')]), len(nov_df[nov_df['Genre 1'].str.contains('alt|alternative') | nov_df['Genre 2'].str.contains('alt|alternative') | nov_df['Genre 3'].str.contains('alt|alternative')]), len(nov_df[nov_df['Genre 1'].str.contains('glitchcore') | nov_df['Genre 2'].str.contains('glitchcore') | nov_df['Genre 3'].str.contains('glitchcore')]), len(nov_df[nov_df['Genre 1'].str.contains('brooklyn drill') | nov_df['Genre 2'].str.contains('brooklyn drill') | nov_df['Genre 3'].str.contains('brooklyn drill')]), len(nov_df[nov_df['Genre 1'].str.contains('halloween') | nov_df['Genre 2'].str.contains('halloween') | nov_df['Genre 3'].str.contains('halloween')]), len(nov_df[nov_df['Genre 1'].str.contains('christmas') | nov_df['Genre 2'].str.contains('christmas') | nov_df['Genre 3'].str.contains('christmas')]), len(nov_df[nov_df['Genre 1'].str.contains('classical') | nov_df['Genre 2'].str.contains('classical') | nov_df['Genre 3'].str.contains('classical')])]\n",
    "}\n",
    "nov_viral_genre_df = pd.DataFrame(genre_data)\n",
    "nov_viral_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nov_viral_genre_df = nov_viral_genre_df.sort_values('Count', ascending=False)\n",
    "sorted_nov_viral_genre_df.head()"
   ]
  },
  {
   "source": [
    "Color coding all the genres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_jan_viral_genre_df[\"Colors\"] = \"\"\n",
    "sorted_jan_viral_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Rap/Hip Hop/Trap', 'R&B/Soul/Blues',  'Pop', 'Rock', 'Country', 'Latin', 'Disco', 'Indie', 'House/EDM', 'Alternative/Alt', 'Glitchcore', 'Brooklyn Drill', 'Halloween', 'Christmas', 'Classical']\n",
    "colors = ['red', 'blue', 'purple', 'orchid', 'orange', 'indianred', 'gold', 'seagreen', 'slateblue', 'coral', 'silver', 'palevioletred', 'limegreen', 'maroon', 'purple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_jan = sorted_jan_viral_genre_df['Genre'].tolist()\n",
    "jan_colors = []\n",
    "\n",
    "for x in genres_jan:\n",
    "    if x == genres[0]:\n",
    "        jan_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        jan_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        jan_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        jan_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        jan_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        jan_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        jan_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        jan_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        jan_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        jan_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        jan_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        jan_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        jan_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        jan_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        jan_colors.append(colors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_mar = sorted_mar_viral_genre_df['Genre'].tolist()\n",
    "mar_colors = []\n",
    "\n",
    "for x in genres_mar:\n",
    "    if x == genres[0]:\n",
    "        mar_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        mar_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        mar_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        mar_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        mar_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        mar_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        mar_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        mar_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        mar_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        mar_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        mar_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        mar_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        mar_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        mar_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        mar_colors.append(colors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_may = sorted_may_viral_genre_df['Genre'].tolist()\n",
    "may_colors = []\n",
    "\n",
    "for x in genres_may:\n",
    "    if x == genres[0]:\n",
    "        may_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        may_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        may_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        may_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        may_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        may_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        may_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        may_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        may_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        may_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        may_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        may_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        may_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        may_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        may_colors.append(colors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_jul = sorted_jul_viral_genre_df['Genre'].tolist()\n",
    "jul_colors = []\n",
    "\n",
    "for x in genres_jul:\n",
    "    if x == genres[0]:\n",
    "        jul_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        jul_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        jul_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        jul_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        jul_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        jul_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        jul_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        jul_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        jul_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        jul_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        jul_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        jul_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        jul_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        jul_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        jul_colors.append(colors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_sep = sorted_sep_viral_genre_df['Genre'].tolist()\n",
    "sep_colors = []\n",
    "\n",
    "for x in genres_sep:\n",
    "    if x == genres[0]:\n",
    "        sep_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        sep_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        sep_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        sep_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        sep_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        sep_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        sep_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        sep_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        sep_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        sep_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        sep_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        sep_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        sep_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        sep_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        sep_colors.append(colors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_nov = sorted_nov_viral_genre_df['Genre'].tolist()\n",
    "nov_colors = []\n",
    "\n",
    "for x in genres_nov:\n",
    "    if x == genres[0]:\n",
    "        nov_colors.append(colors[0])\n",
    "    if x == genres[1]:\n",
    "        nov_colors.append(colors[1])\n",
    "    if x == genres[2]:\n",
    "        nov_colors.append(colors[2])      \n",
    "    if x == genres[3]:\n",
    "        nov_colors.append(colors[3]) \n",
    "    if x == genres[4]:\n",
    "        nov_colors.append(colors[4])\n",
    "    if x == genres[5]:\n",
    "        nov_colors.append(colors[5])\n",
    "    if x == genres[6]:\n",
    "        nov_colors.append(colors[6])\n",
    "    if x == genres[7]:\n",
    "        nov_colors.append(colors[7]) \n",
    "    if x == genres[8]:\n",
    "        nov_colors.append(colors[8])\n",
    "    if x == genres[9]:\n",
    "        nov_colors.append(colors[9])\n",
    "    if x == genres[10]:\n",
    "        nov_colors.append(colors[10])\n",
    "    if x == genres[11]:\n",
    "        nov_colors.append(colors[11])\n",
    "    if x == genres[12]:\n",
    "        nov_colors.append(colors[12])\n",
    "    if x == genres[13]:\n",
    "        nov_colors.append(colors[13])\n",
    "    if x == genres[14]:\n",
    "        nov_colors.append(colors[14])"
   ]
  },
  {
   "source": [
    "Create bar charts as subplots for visualization of genre behavior across months."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_x = sorted_jan_viral_genre_df['Genre']\n",
    "jan_y = sorted_jan_viral_genre_df['Count']\n",
    "\n",
    "mar_x = sorted_mar_viral_genre_df['Genre']\n",
    "mar_y = sorted_mar_viral_genre_df['Count']\n",
    "\n",
    "may_x = sorted_may_viral_genre_df['Genre']\n",
    "may_y = sorted_may_viral_genre_df['Count']\n",
    "\n",
    "jul_x = sorted_jul_viral_genre_df['Genre']\n",
    "jul_y = sorted_jul_viral_genre_df['Count']\n",
    "\n",
    "sep_x = sorted_sep_viral_genre_df['Genre']\n",
    "sep_y = sorted_sep_viral_genre_df['Count']\n",
    "\n",
    "nov_x = sorted_nov_viral_genre_df['Genre']\n",
    "nov_y = sorted_nov_viral_genre_df['Count']\n",
    "\n",
    "# fig, (ax1,ax2,ax3,ax4,ax5,ax6) = plt.subplots(2,3, sharey=True)\n",
    "fig = plt.figure(figsize = (20, 15))\n",
    "fig.add_axes()\n",
    "\n",
    "ax1 = fig.add_subplot(231)\n",
    "ax1.bar(jan_x, jan_y, color=jan_colors, zorder=2)\n",
    "ax1.grid(alpha=0.5, zorder=0)\n",
    "ax1.xaxis.set(ticks=range(len(jan_x)))\n",
    "# ax1.setxticklabels(jan_x, rotation=90)\n",
    "ax1.tick_params(axis='y', direction='inout', length=10)\n",
    "ax1.tick_params(axis='x', direction='inout', length=10, labelrotation=90)\n",
    "ax1.set(title=\"January\")\n",
    "# ax1.set_xlabel('Genre', fontsize=14)\n",
    "ax1.set_ylabel('Counts', fontsize=14)\n",
    "\n",
    "ax2 = fig.add_subplot(232, sharey=ax1)\n",
    "ax2.bar(mar_x, mar_y, color=mar_colors, zorder=2)\n",
    "ax2.grid(alpha=0.5, zorder=0)\n",
    "ax2.xaxis.set(ticks=range(len(mar_x)))\n",
    "# ax1.setxticklabels(jan_x, rotation=90)\n",
    "# ax2.tick_params(axis='y', direction='inout', length=10)\n",
    "ax2.tick_params(axis='x', direction='inout', length=10, labelrotation=90)\n",
    "ax2.set(title=\"March\")\n",
    "# ax2.set_xlabel('Genre', fontsize=14)\n",
    "# ax2.set_ylabel('Counts', fontsize=14)\n",
    "\n",
    "\n",
    "ax3 = fig.add_subplot(233, sharey=ax1)\n",
    "ax3.bar(may_x, may_y, color=may_colors, zorder=2)\n",
    "ax3.grid(alpha=0.5, zorder=0)\n",
    "ax3.xaxis.set(ticks=range(len(may_x)))\n",
    "# ax1.setxticklabels(jan_x, rotation=90)\n",
    "# ax3.tick_params(axis='y', direction='inout', length=10)\n",
    "ax3.tick_params(axis='x', direction='inout', length=10, labelrotation=90)\n",
    "ax3.set(title=\"May\")\n",
    "# ax3.set_xlabel('Genre', fontsize=14)\n",
    "# ax3.set_ylabel('Counts', fontsize=14)\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(234)\n",
    "ax4.bar(jul_x, jul_y, color=jul_colors, zorder=2)\n",
    "ax4.grid(alpha=0.5, zorder=0)\n",
    "ax4.xaxis.set(ticks=range(len(jul_x)))\n",
    "# ax1.setxticklabels(jan_x, rotation=90)\n",
    "ax4.tick_params(axis='y', direction='inout', length=10)\n",
    "ax4.tick_params(axis='x', direction='inout', length=10, labelrotation=90)\n",
    "ax4.set(title=\"July\")\n",
    "# ax4.set_xlabel('Genre', fontsize=14)\n",
    "ax4.set_ylabel('Counts', fontsize=14)\n",
    "\n",
    "\n",
    "ax5 = fig.add_subplot(235, sharey=ax4)\n",
    "ax5.bar(sep_x, sep_y, color=sep_colors, zorder=2)\n",
    "ax5.grid(alpha=0.5, zorder=0)\n",
    "ax5.xaxis.set(ticks=range(len(sep_x)))\n",
    "# ax1.setxticklabels(jan_x, rotation=90)\n",
    "# ax5.tick_params(axis='y', direction='inout', length=10)\n",
    "ax5.tick_params(axis='x', direction='inout', length=10, labelrotation=90)\n",
    "ax5.set(title=\"September\")\n",
    "# ax5.set_xlabel('Genre', fontsize=14)\n",
    "# ax5.set_ylabel('Counts', fontsize=14)\n",
    "\n",
    "\n",
    "ax6 = fig.add_subplot(236, sharey=ax4)\n",
    "ax6.bar(nov_x, nov_y, color=nov_colors, zorder=2)\n",
    "ax6.grid(alpha=0.5, zorder=0)\n",
    "ax6.xaxis.set(ticks=range(len(nov_x)))\n",
    "# ax1.setxticklabels(jan_x, rotation=90)\n",
    "# ax6.tick_params(axis='y', direction='inout', length=10)\n",
    "ax6.tick_params(axis='x', direction='inout', length=10, labelrotation=90)\n",
    "ax6.set(title=\"November\")\n",
    "# ax6.set_xlabel('Genre', fontsize=12)\n",
    "# ax6.set_ylabel('Counts', fontsize=14)\n",
    "\n",
    "fig.suptitle('Distribution of Viral Song Genres in 2020', fontsize=14)\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.15, hspace=0.5)\n",
    "# plt.bar(names, values, color=['red', 'blue', 'purple', 'orchid', 'orange', 'indianred', 'gold', 'seagreen', 'slateblue', 'coral', 'silver', 'palevioletred', 'limegreen'], zorder=2)\n",
    "# plt.xticks(rotation=90, size=14)\n",
    "# plt.grid(alpha=0.5, zorder=0)\n",
    "# plt.yticks(size=14)\n",
    "# plt.ylabel(\"Counts\", size=14)\n",
    "# plt.title(\"Total Distribution of Viral Song Genres for Sampled Months in 2020\", size=18)\n",
    "# plt.setp(axa.xaxis.get_majorticklabels(), rotation=95)\n",
    "# plt.subplot(221)\n",
    "\n",
    "plt.gcf()\n",
    "plt.show()\n",
    "fig.savefig('total_months_viral_genre.jpg', facecolor='w', dpi=400)"
   ]
  },
  {
   "source": [
    "## Unemployment Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting CSV, creating dataframes, cleaning and plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df = pd.read_csv('csv file/UI_weekly_2020.csv', skiprows=[0,1],skip_blank_lines=True, skipinitialspace=True)\n",
    "ui_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df = ui_df.rename(columns={'Unnamed: 0': \"Date\"})\n",
    "ui_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df.convert_dtypes(infer_objects=True, convert_integer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_df_dropped = ui_df.dropna(how='all')\n",
    "ui_df_dropped.apply(pd.to_numeric, errors='coerce')\n",
    "ui_df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui2_df_dropped = ui_df_dropped[(ui_df_dropped.Date != 'Run Date: 4/28/2021')]\n",
    "ui2_df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ui_df = ui2_df_dropped.copy()\n",
    "new_ui_df['Week Number'] = \"\"\n",
    "new_ui_df['Date'] = pd.to_datetime(new_ui_df['Date'], errors='coerce')\n",
    "new_ui_df['N.S.A'] = new_ui_df['N.S.A'].str.replace(',', '').astype(int)\n",
    "new_ui_df['S.A.'] = new_ui_df['S.A.'].str.replace(',', '').astype(int) # to completely convert it to a string\n",
    "new_ui_df[\"Week Number\"] = new_ui_df['Date'].dt.week\n",
    "new_ui_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_num = new_ui_df[\"Week Number\"].tolist()\n",
    "print(week_num)"
   ]
  },
  {
   "source": [
    "Obtaining top 200 information to obtain the strea numbers per week to put the graph comparing its trend to unemployment claims"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_all = pd.read_csv('csv files/top200_all_months.csv')\n",
    "streams_all = streams_all.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "streams_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_all_sum = streams_all.groupby('Week Number')['Streams'].sum()\n",
    "print(streams_all_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_streams = streams_all_sum.astype(float).to_list()\n",
    "weeks = pd.DataFrame(streams_all.groupby('Week Number').count())\n",
    "print(num_streams)\n",
    "weeks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_list = weeks_reindex['Week Number'].to_list()\n",
    "print(weeks_list)\n",
    "print(len(num_streams))\n",
    "print(len(weeks_list))"
   ]
  },
  {
   "source": [
    "Create unemployment claims plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_UI= week_num\n",
    "y_UI= new_ui_df['S.A.']\n",
    "\n",
    "fig = plt.figure(figsize = (15, 20))\n",
    "fig.add_axes()\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(x_UI, y_UI, zorder=2, color='red')\n",
    "ax1.grid(alpha=0.5, zorder=0)\n",
    "ax1.xaxis.set(ticks=range(len(x_UI)))\n",
    "\n",
    "\n",
    "ax1.set_xlabel('Weeks', fontsize=16)\n",
    "\n",
    "ax1.tick_params(axis='y', direction='inout', length=10, size=14)\n",
    "ax1.tick_params(axis='x', direction='inout', length=10, size=14)\n",
    "# ax1.set(title=\"Weekly Unemployment Insurance Claims in 2020\")\n",
    "ax1.set_title('Weekly Unemployment Insurance Claims in 2020', fontsize=20)\n",
    "\n",
    "ax1.set_ylabel('Number of Weekly Unemployment Claims (Seasonally Adjusted)', fontsize=16)\n",
    "\n",
    "# plt.gcf().set_size_inches(20,20)\n",
    "plt.tight_layout()\n",
    "fig.savefig('2020_Weekly_UI.png', facecolor='w', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Combine bar graph of streams per week and line graph of unemplyment claims"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.geeksforgeeks.org/how-to-add-a-y-axis-label-to-the-secondary-y-axis-in-matplotlib/\n",
    "x = week_num\n",
    "x2 = weeks_list\n",
    "# y-axis values\n",
    "y1 = new_ui_df['S.A.']\n",
    "  \n",
    "# secondary y-axis values\n",
    "y2 = num_streams\n",
    "  \n",
    "# plotting figures by creating aexs object\n",
    "# using subplots() function\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "plt.title('Unemployment Claims and Streams per Week', size=20)\n",
    "  \n",
    "# using the twinx() for creating another\n",
    "# axes object for secondry y-Axis\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(x, y1, color = 'indianred', alpha=1)\n",
    "ax2.bar(x2, y2, color = 'seagreen', alpha=0.4)\n",
    "  \n",
    "# giving labels to the axises\n",
    "ax.set_xlabel('Weeks', size=16)\n",
    "ax.set_ylabel('Number of Unemployment Claims', size=16)\n",
    "  \n",
    "# secondary y-axis label\n",
    "ax2.set_ylabel('Streams', size=16)\n",
    "  \n",
    "# defining display layout \n",
    "plt.tight_layout()\n",
    "  \n",
    "# show plot\n",
    "\n",
    "\n",
    "fig.savefig('2020_Weekly_UIvsStreams.png', facecolor='w', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Create correlation and scatter plot for UI vs streams per week"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_ui=[]\n",
    "all_wks_claims = new_ui_df['S.A.'].astype(float).to_list()\n",
    "print(all_wks_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_week_list = weeks_reindex['Week Number'].to_list()\n",
    "print(songs_week_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(week_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_claim_dict = dict(zip(week_num, all_wks_claims))\n",
    "print(week_claim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find only the claims number that match the same week in the songs\n",
    "for x, y in week_claim_dict.items():\n",
    "    n = 0\n",
    "    for n in range(len(songs_week_list)):\n",
    "        if x == songs_week_list[n]:\n",
    "            claims_ui.append(int(y))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(claims_ui)\n",
    "print(len(claims_ui))\n",
    "# print(claims_ui[0].type())\n",
    "print(len(weeks_list))\n",
    "print(num_streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([210000, 206000, 219000, 210000, 216000, 212000, 256000, 2923000, 2784000, 2315000, 2149000, 1887000, 1398000, 1479000, 1398000, 1262000, 881000, 860000, 860000, 803000, 728000, 732000, 762000, 719000])\n",
    "y= np.array([568732447.0, 630848180.0, 699004731.0, 608490489.0, 632716011.0, 690261593.0, 590879939.0, 572606856.0, 567969812.0, 525600167.0, 532625341.0, 522477928.0, 512651814.0, 637517013.0, 541592640.0, 659279693.0, 510979316.0, 494926568.0, 493853348.0, 508319217.0, 482611166.0, 483252803.0, 514674608.0, 543690539.0])\n",
    "\n",
    "(slope,intercept,r_value,pvalue,stderr)=st.linregress(x,y)\n",
    "slope = int(slope)\n",
    "regress_values=x*slope+intercept\n",
    "line_eq=\"y = \"+str(round(slope,2))+\" x + \"+str(round(intercept,2))\n",
    "\n",
    "print(f'The line equation is {line_eq}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax = plt.scatter(x,y, color='purple')\n",
    "ax = plt.plot(x,regress_values,\"indianred\")\n",
    "ax = plt.text(1000000,620000000, line_eq, size=14, color='b')\n",
    "plt.xlabel('Number of Weekly Unemployment Claims', size=12)\n",
    "plt.ylabel('Number of Total Streams per Week', size=12)\n",
    "plt.tight_layout(pad=3.5)\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.title('Linear Regression for Weekly Unemployment Claims vs \\nTotal Streams per Week in Samples 2020 Months', size=20)\n",
    "\n",
    "print(f\"The r-squared is: {r_value**2:.2f}\")\n",
    "plt.savefig('correlation.jpg', facecolor='w', edgcolor='w', dpi=600)\n",
    "plt.show()"
   ]
  }
 ]
}